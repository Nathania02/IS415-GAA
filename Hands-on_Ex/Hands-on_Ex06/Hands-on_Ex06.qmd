---
title: "Hands-on Ex 6: Global and Local Measures of Spatial Autocorrelation"
author: "Nathania Yeo"
date: "September 19, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  freeze: true
---

# 1.0 Overview

In this hands-on exercise, I will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. At the end of this hands-on exercise, I will be able to:

-   import geospatial data using appropriate function(s) of sf package,

-   import csv file using appropriate function of readr package,

-   perform relational join using appropriate join function of dplyr package,

-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,

    -   plot Moran scatterplot,

    -   compute and plot spatial correlogram using appropriate function of spdep package

-   provide statistically correct interpretation of GSA statistics.

In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”

In this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.

# 2.0 Setup for exercise

## 2.1 Data Acquisition

Two datasets will be used. Hunan province administrative boundary layer at county level and Hunan_2012.csv which contains selected Hunan's local development indicators in 2012.

## 2.2 R packages

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

# 3.0 Import Data into R

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

```{r}
hunan_2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

## 3.1 Perform relational join

```{r}
hunan <- left_join(hunan, hunan_2012) %>%
  select(1:4, 7, 15)
```

## 3.2 Visualising Regional Development Indicator

I will prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.

```{r}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

# 4.0 Global Measures of Spatial Autocorrelation

## 4.1 Computing Contiguity Spatial Weights

Before computing the global spatial autocorrelation statistics, spatial weights of the study area need to be constructed. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e county) in the study area.

In the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. From the documentation, useres can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.

The code chunk below is used to compute Queen contiguity weight matrix.

```{r}
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are 2 area units with only one neighbours.

## 4.2 Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In this case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.

```{r}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

# 5.0 Global Measures of Spatial Autocorrelation: Moran's I

## 5.1 Maron's I test

The code chunk below performs Moran's I statistical testing using moran.test() of spdep.

```{r}
moran.test(hunan$GDPPC, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

It shows that there is a weak positive spatial autocorrelation in the variable GDPPC, where regions with similar values tend to be spatially clustered together.

## 5.2 Computing Monte Carlo Moran's I

The code chunk below performs permutation test for Moran's I statistic by using moran.mc() od spdep. A total of 1000 simulation will be performed.

```{r}
set.seed(1234)
bperm= moran.mc(hunan$GDPPC, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

The p-value is less than 0.05 which means that the spatial pattern observed is unlikely to be the result of random chance. Hence, the null hypothesis of no spatial autocorrelation is rejected. The areas with similar values of GDPPC are more likely to be located near each other.

## 5.3 Visualising Monte Carlo Moran's I

It is a good practice to examine the simulated Moran's I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below. In the code chunk below hist() and abline() of R graphics are used.

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

The mean of simulated Moran's I statistics is -0.01504572. This is close to 0 which is what is expected under the null hypothesis of spatial randomness. The variance is 0.004371574. This gives us an idea of the spread of the Moran's I statistics under the null hypothesis. The histogram provide a visual representation, with a vertical reed line at 0 to represent the expected value under the null hypothesis.

```{r}
df <- data.frame(MoranI = bperm$res[1:999])
ggplot(df, aes(x = MoranI)) +
  geom_histogram(bins = 20, fill = "grey", color = "black") +
  geom_vline(aes(xintercept = 0.05), color = "red", linetype = "dashed") +
  xlab("Simulated Moran's I") +
  ylab("Frequency") +
  ggtitle("Histogram of Simulated Moran's I")
```

# 6.0 Global Measures of Spatial Autocorrelation: Geary's C

## 6.1 Geary's C test

```{r}
geary.test(hunan$GDPPC, listw=rswm_q)
```

The Geary's C statistics is 0.6907223, which is significantly different from the expectation under the null hypothesis is 1. It suggests that there is a significant local spatial structure in the data. The standard deviation is 3.6108. The p-value is less than 0.05 which indicates that the spatial pattern is unlikely to be the result of random chance. We reject the null hypothesis of no spatial autocorrelation. Ths areas with similar values are more likely to be clustered than randomly distributed.

## 6.2 Computing Monte Carlo Geary's C

```{r}
set.seed(1234)
bperm=geary.mc(hunan$GDPPC, 
               listw=rswm_q, 
               nsim=999)
bperm
```

The p-value is less than 0.05 which means that the pattern is unlikely to be result of the random chance. The null hypothesis of no spatial autocorrelation is rejected. The areas with similar values are more likely to be located near each other.

## 6.3 Visualising the Monte Carlo Geary's C

```{r}
mean(bperm$res[1:999])
```

```{r}
var(bperm$res[1:999])
```

```{r}
summary(bperm$res[1:999])
```

```{r}
hist(bperm$res, freq=TRUE, breaks=20, xlab="Simulated Geary c")
abline(v=1, col="red") 
```

The mean is 1.004402 which is close to 0 and this is what we would expect under the null hypothesis of spatial randomness. The variance is 0.007436493 which tells the spread under the null hypothesis. With the vertical red line at Geary's C=1 in the histogram, it represents the expected value under the null hypothesis of no spatial autocorrelation.

# 7.0 Spatial Correlogram

Spatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.

## 7.1 Compute Moran's I correlogram

In the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.

```{r}
MI_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="I", 
                          style="W")
plot(MI_corr)
```

By plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.

```{r}
print(MI_corr)
```

The p-values are less than 0.05 for lags 1, 2, 3, 5, 6 which indicates that the spatial autocorrelation at these distances is statistically significant. For lag 4, the p-value is greater than 0.05, which shows that the spatial autocorrelation at this distance is not statistically significant. For lag 1 to 4, the statistic is positive which proves positive spatial autocorrelation at these distances. For lag 5 and 6, the statistic is negative which indicates negative spatial autocorrelation at these distances.

## 7.2 Compute Geary's C correlogram and plot

In the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.

```{r}
GC_corr <- sp.correlogram(wm_q, 
                          hunan$GDPPC, 
                          order=6, 
                          method="C", 
                          style="W")
plot(GC_corr)
```

Similar to the previous step, we will print out the analysis report by using the code chunk below.

```{r}
print(GC_corr)
```

# 8.0 Local Measures of Spatial Autocorrelation

Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the map. In this sense, they are not summary statistics but scores that allow us to learn more about the spatial structure in our data. The general intuition behind the metrics however is similar to that of global ones. Some of them are even mathematically connected, where the global version can be decomposed into a collection of local ones. One such example are Local Indicators of Spatial Association (LISA). Beside LISA, Getis-Ord’s Gi-statistics will be introduce as an alternative LMSA statistics that present complementary information or allow us to obtain similar insights for geographically referenced data.

In this hands-on exercise, I will learn how to compute Local Measures of Spatial Autocorrelation (LMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:

-   import geospatial data using appropriate function(s) of sf package,

-   import csv file using appropriate function of readr package,

-   perform relational join using appropriate join function of dplyr package,

-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;

-   compute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and

-   to visualise the analysis output by using tmap package.

# 9.0 Local Indicators of Spatial Association (LISA)

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, you will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

## 9.1 Computing COntiguity Spatial Weights
```{r}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```
## 9.2 Row-standardised weights matrix
```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```


## 9.3 Computing local Moran's I

To compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

The code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

localmoran() function returns a matrix of values whose columns are:

Ii: the local Moran’s I statistics 
E.Ii: the expectation of local moran statistic under the randomisation hypothesis 
Var.Ii: the variance of local moran statistic under the randomisation hypothesis 
Z.Ii:the standard deviate of local moran statistic 
Pr(): the p-value of local moran statistic 

The code chunk below list the content of the local Moran matrix derived by using printCoefmat().

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=hunan$County[fips]),
  check.names=FALSE)
```

### 9.3.1 Mapping the local Moran's I

Before mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

### 9.3.2 Mapping local Moran's I values

Using choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

### 9.3.3 Mapping local Moran's I p-values

The choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

The code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

### 9.3.4 Mapping both local Moran's I values and p-values

For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.

The code chunk below will be used to create such visualisation.

```{r}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

# 10.0 Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

## 10.1 Plotting Moran's scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

The code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
        labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

Notice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.

## 10.2 Plotting Moran scatterplot with standardised variable

First we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% 
  as.vector 
```

The as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.

Now, we are ready to plot the Moran scatterplot again by using the code chunk below.

```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,                  labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

## 10.3 Preparing LISA map classes

```{r}
#| eval: false
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Next, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.

```{r}
#| eval: false
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC) 
```

This is follow by centering the local Moran's around the mean.

```{r}
#| eval: false
LM_I <- localMI[,1] - mean(localMI[,1])    
```

Next, we will set a statistical significance level for the local Moran.

```{r}
#| eval: false
signif <- 0.5
```

These four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

```{r}
#| eval: false
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      
```

Lastly, places non-significant Moran in the category 0.

```{r}
#| eval: false
quadrant[localMI[,5]>signif] <- 0
```

In fact, we can combined all the steps into one single code chunk as shown below:

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     
LM_I <- localMI[,1]-mean(localMI[,1])   
signif <- 0.05       
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4    
quadrant[localMI[,5]>signif] <- 0
```

## 10.4 Plotting LISA map

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI)+
  tm_fill(col = "quadrant",
          style="cat",
          palette=colors[c(sort(unique(quadrant)))+1],
          labels=clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c(""))+
  tm_view(set.zoom.limits=c(11,17)) +
  tm_borders(alpha=0.5)
```

For effective interpretation, it is better to plot both the local Moran's I values map and its corresponding p-values map next to each other.

```{r}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant",
          style = "cat",
          palette = colors[c(sort(unique(quadrant)))+1],
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap,
             asp=1, ncol=2)
```

We can also include the local Moran's I map and p-value map for easy comparison.

```{r}
tmap_arrange(gdppc, LISAmap,localMI.map, pvalue.map, asp=2, ncol=2)
```

From the LISA map above, the areas tht are coloured red (high-high) are hot spots where there is signs of clustering. Both the location and neighbours have high values which indicates the region of high GDP per capita. On the other hand, those areas coloured blue (low-low) are cold spots where the location and neighbours have low values, indicating random distribution.

For areas that are coloured orange (low-high), it may be outliers or transition areas which need further investigation. Those coloured in teal (high-low) are transition areas where the values is high but the neighbours values is low. Those areas coloured in white do not show significant local spatial association and do not fit into any clusters.


# 11.0 Hot Spot and Cold Spot Area analysis

Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).

## 11.1 Getis and Ord's G-Statistics

An alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

The analysis consists of three steps:

-   Deriving spatial weight matrix

-   Computing Gi statistics

-   Mapping Gi statistics

## 11.2 Deriving distance-based weight matrix

First, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.

There are two type of distance-based proximity matrix, they are:

-   fixed distance weight matrix; and

-   adaptive distance weight matrix.

### 11.2.1 Deriving the centroid

The points need to associate with each polygon before I can make the connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. I need the coordinates in a separate data frame for this to work. To do this I will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. My input vector will be the geometry column of us.bound. My function will be st_centroid(). I will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation

To get the longitude values I map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation \[\[\]\] and 1. This allows me to get only the longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Now that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

### 11.2.2 Determine the cut-off distance

Firstly, we need to determine the upper limit for distance band by using the steps below:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.

-   Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().

-   Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

-   Remove the list structure of the returned object by using unlist().

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

### 10.2.3 Computing fixed distance weight matrix

Now, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Next, nb2listw() is used to convert the nb object into spatial weights object.

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

The output spatial weights object is called wm62_lw.

## 11.3 Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Next, nb2listw() is used to convert the nb object into spatial weights object.

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

# 12.0 Computing Gi statistics

## 12.1 Gi statistics using fixed distance

```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

The output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.

The Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.

Next, I will join the Gi values to their corresponding hunan sf data frame.

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

In fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan\@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().

## 12.2 Mapping Gi values with fixed distance weights

The code chunk below shows the function used to map the Gi values derived using fixed distance weight matrix.

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

From the plots above, there are hot spots in the northeast. There are also cold spots that were previously not visible when using a distance weight matrix derived with a fixed bandwidth of 62km. 

## 12.3 Gi statistics using adaptive distance

The code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

## 12.4 Mapping Gi values with adaptive distance weights

It is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r}
gdppc<- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, 
             Gimap, 
             asp=1, 
             ncol=2)
```

Similarly to the plot above, the hot spots are in the northeast. The cold spots are in the south west area. 
